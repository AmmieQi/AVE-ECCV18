Audio-Visual Event Localization in Unconstrained Videos (To appear in ECCV 2018)

### AVE Dataset & Features

AVE dataset can be downloaded from https://drive.google.com/open?id=1FjKwe79e0u96vdjIVwfRQ1V6SoDHe7kK.

Audio feature, visual feature, one-hot labels, and train/val/test lists can be found in .




### CitationS

If you find this work useful, please consider citing it.

 > @inproceedings{AVE2018, <br>
 >    title={Audio-Visual Event Localization in Unconstrained Videos},<br>
 >   author={Yapeng Tian, Jing Shi, Bochen Li, Zhiyao Duan, and Chenliang Xu},<br>
 >    booktitle={ECCV},<br>
 >   year={2018}<br>
 > }
 
 
 ### Acknowledgements
 
Audio features are extracted using [Vggish](https://github.com/tensorflow/models/tree/master/research/audioset) and the audio-guided visual attention model was implemented highly based on [adaptive attention](https://github.com/jiasenlu/AdaptiveAttention). We thank the authors for sharing their codes.
 



